

# 客户端连接一个不存在的 IP 地址，会发生什么？
这里的「连接」指的是 TCP 连接。

这个问题要分两种情况来思考，不同的情况得到的结论是不同的。

## 第一个情况：目标 IP 地址和客户端的 IP 地址是同一个局域网（网络号相同）。
第一种情况，客户端无法发出 SYN 报文，主要卡在数据链路层。

因为目标地址不存在 IP 地址，客户端的内核在发`arp`请求的时候，广播询问这个目标 IP 地址是谁的，由于网络中不存在该目标 IP 地址，所以没有设备应答客户端的`arp`请求。

由于客户端无法拿到目标设备的 MAC，这样就没办法组装 MAC 头的信息，所以 SYN 报文无法发送出去。

第二个情况：目标 IP 地址和客户端的 IP 地址不在同一个局域网（网络号不同）。

第二种情况，客户端会先将 SYN 报文发给路由器，然后路由器会继续转发。

由于目标 IP 地址是不存在的，该 SYN 报文会在网络中消亡，因此客户端是不会收到对 SYN 报文的确认报文的，接着客户端会触发超时重传，重传 SYN 报文，直到重传的次数达到最大次数后，客户端的连接就会被释放。

为什么这种情况客户端的 SYN 报文可以发出来？

因为当目标 IP 地址和客户端 IP 地址不在同一个局域网时，客户端通过路由表的判断，判断到下一步是要将网络报文发送给路由器。

这时候数据链路层的`arp`请求，会广播询问 IP 地址（路由器 IP 地址）是谁的，路由器发现是自己的 IP 地址，于是就会将自己的 MAC 地址告诉客户端。

然后客户端的网络报文中 MAC 头的「目标 MAC 地址」填入的就是路由器的 MAC 地址，于是`SYN`报文就可以发送出去了。

由于目标 MAC 地址是路由器的，所以就会被路由器接收，然后路由器继续通过路由表的判断，转发给下一个路由器，直到找到目标设备。
# 客户端连接一个存在的 IP 地址但是端口不存在，会发生什么？
客户端连接的目标 IP 地址是存在的，那么`SYN`报文就能正确的抵达到目标设备。

目标设备收到`SYN`报文后，发现端口号并没有被进程监听，这时候目标设备的内核就会回`RST`报文。

客户端收到`RST`报文后，就会释放连接。
# 客户端发送了一个目标 IP 地址存在但是端口不存在的 UDP 报文，UDP 没有像 TCP 那样的 RST 报文，此时会发生什么？
当 UDP 发送一个目标 IP 地址存在但是端口不存在的报文时，接收主机会发送一个 ICMP 端口不可达报文，以通知发送主机该端口不存在。
# 为什么在 TCP 三次握手过程中，如果客户端收到的 SYN-ACK 报文的确认号不符合预期的话，为什么是回 RST，而不是丢弃呢？
{% asset_img 1.png %}

描述下这个场景：
* 客户端向服务端发送`SYN`报文（`seq=100`），但是网络中有个不速之客，一个历史的`SYN`报文（`seq=90`）先抵达服务端；
* 服务端收到历史的`SYN`报文，就会对此`SYN`报文做了确认，回了`SYN-ACK`报文，确认号为`90+1`；
* 客户端收到`SYN-ACK`报文后，诶发现不对劲，他明明发的是`SYN`报文（`seq=100`），按道理`SYN-ACK`报文中的确认号是`100+1`，可现在收到的确认号为`90+1`的`SYN-ACK`报文，所以礼貌地回了`RST`给服务端；
* 服务端收到`RST`报文后，服务端就断开处于`SYN_RECEVIED`状态的连接；
* 最后正常的`SYN`报文（`seq=100`）终于抵达了服务端，经过三次握手后，双方的 TCP 连接都建立完成。
* 
上面这个过程，就是 TCP 三次握手防止历史连接建立的过程，之所以 TCP 需要三次握手，首要原因是为了防止旧的重复连接初始化造成混乱，其次原因是可靠的同步双方的序列号。

那为什么要设计成，当客户端收到不符合期望的`SYN-ACK`报文，是回`RST`，而不是丢弃呢？

现在我们来假设是丢弃处理，看看会发生什么？

{% asset_img 2.jpg %}

可以看到，当处于`SYN_SENT`状态连接的客户端收到不符合期望的`SYN-ACK`报文时，如果选择的处理是「丢弃」，那么双方都会触发超时重传，直到达到最大的重传次数才会进入`CLOSE`状态，这个过程需要持续 10-20 秒。

从客户端的角度看，就是迟迟与服务端建立不来连接，因为服务端这边已经存在一个相同四元组的旧连接，如果不把服务端这个连接干掉，那么是无法确认客户端新的连接（`SEQ=100`），因为非`LISTEN`状态下，如果收到`SYN`，都是回`challenge ack`，这个`ack`并不是对收到`SYN`报做确认，而是继续回复上一次已发送`ACK`。

所以干掉服务端的旧连接的工作，就交给了客户端来做了。

当处于`SYN_SENT`状态连接的客户端，在收到不符合期望的`SYN-ACK`报文时，就直接`RST`给服务端，干掉服务端的旧连接，这样客户端的新连接才能快速建立。

# 断网了，还能 ping 通 127.0.0.1 吗？
## 什么是127.0.0.1
127 开头的都属于回环地址，也是 IPV4 的特殊地址，没什么道理，就是人为规定的。而127.0.0.1是众多回环地址中的一个。之所以不是 127.0.0.2 ，而是 127.0.0.1，是因为源码里就是这么定义的，也没什么道理。
```
/* Address to loopback in software to local host.  */
#define    INADDR_LOOPBACK     0x7f000001  /* 127.0.0.1   */
```
在IPV4下的回环地址是 127.0.0.1，在IPV6下，表达为 ::1 。中间把连续的0给省略了，之所以不是7个 冒号，而是2个冒号: ， 是因为一个 IPV6 地址中只允许出现⼀次两个连续的冒号。

在IPV4下用的是 ping 127.0.0.1 命令。在IPV6下用的是 ping6  ::1 命令。
## 什么是 ping
`ping`是应用层命令，它的功能比较简单，就是尝试发送一个小小的消息到目标机器上，判断目的机器是否可达，其实也就是判断目标机器网络是否能连通。

`ping`应用的底层，用的是网络层的ICMP协议。

虽然 ICMP 协议和 IP 协议都属于网络层协议，但其实 ICMP 也是利用了IP协议进行消息的传输。所以，可以简单的理解为`ping`某个IP 就是往某个IP地址发个消息。

## TCP发数据和ping的区别
一般情况下，我们会使用 TCP 进行网络数据传输，那么我们可以看下它和 ping 的区别。

{% asset_img 2.png %}

`ping`和其他应用层软件都属于应用层。

那么我们横向对比一下，比方说聊天软件，如果用的是 TCP 的方式去发送消息。

为了发送消息，那就得先知道往哪发。linux 里万物皆文件，那你要发消息的目的地，也是个文件，这里就引出了`socket`的概念。

要使用`socket`, 那么首先需要创建它。

在 TCP 传输中创建的方式是`socket(AF_INET, SOCK_STREAM, 0);`，其中`AF_INET`表示将使用 IPV4 里`host:port`的方式去解析待会你输入的网络地址。`SOCK_STREAM`是指使用面向字节流的 TCP 协议，工作在传输层。

创建好了`socket`之后，就可以愉快的把要传输的数据写到这个文件里。调用`socket`的`sendto`接口的过程中进程会从用户态进入到内核态，最后会调用到`sock_sendmsg`方法。

然后进入传输层，带上 TCP 头。网络层带上 IP 头，数据链路层带上 MAC 头等一系列操作后。进入网卡的发送队列`ring buffer`，顺着网卡就发出去了。

回到`ping`， 整个过程也基本跟 TCP 发数据类似，差异的地方主要在于，创建`socket`的时候用的是`socket(AF_INET,SOCK_RAW,IPPROTO_ICMP)`，`SOCK_RAW`是原始套接字 ，工作在网络层， 所以构建ICMP（网络层协议）的数据，是再合适不过了。`ping`在进入内核态后最后也是调用的`sock_sendmsg`方法，进入到网络层后加上ICMP和IP头后，数据链路层加上MAC头，也是顺着网卡发出。因此 本质上`ping`跟普通应用发消息 在程序流程上没太大差别。

这也解释了为什么当你发现怀疑网络有问题的时候，别人第一时间是问你能`ping`通吗？因为可以简单理解为`ping`就是自己组了个数据包，让系统按着其他软件发送数据的路径往外发一遍，能通的话说明其他软件发的数据也能通。

## 为什么断网了还能 ping 通 127.0.0.1
前面提到，有网的情况下，`ping`最后是通过网卡将数据发送出去的。

那么断网的情况下，网卡已经不工作了，`ping`回环地址却一切正常，我们可以看下这种情况下的工作原理。

{% asset_img 3.png ping回环地址 %}

从应用层到传输层再到网络层。这段路径跟`ping`外网的时候是几乎是一样的。到了网络层，系统会根据目的IP，在路由表中获取对应的路由信息，而这其中就包含选择哪个网卡把消息发出。

当发现目标 IP 是外网 IP 时，会从"真网卡"发出。

当发现目标 IP 是回环地址时，就会选择本地网卡。

本地网卡，其实就是个"假网卡"，它不像"真网卡"那样有个`ring buffer`什么的，"假网卡"会把数据推到一个叫`input_pkt_queue`的链表中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个软中断。

专门处理软中断的工具人`ksoftirqd`（这是个内核线程），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。

`ping`回环地址和通过 TCP 等各种协议发送数据到回环地址都是走这条路径。整条路径从发到收，都没有经过"真网卡"。之所以`127.0.0.1`叫本地回环地址，可以理解为，消息发出到这个地址上的话，就不会出网络，在本机打个转就又回来了。所以断网，依然能`ping`通`127.0.0.1`。
## ping回环地址和ping本机地址有什么区别
执行`ifconfig`。
```
lo0: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10<host>
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 31224  bytes 23501683 (22.4 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 31224  bytes 23501683 (22.4 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
enp4s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.16.10.210  netmask 255.255.255.0  broadcast 172.16.10.255
        inet6 fe80::b943:c1ad:5fd6:faf4  prefixlen 64  scopeid 0x20<link>
        ether 94:09:d3:11:47:73  txqueuelen 1000  (Ethernet)
        RX packets 2086813  bytes 810892043 (773.3 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 2464484  bytes 654013857 (623.7 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        device memory 0xdfd00000-dfd1ffff  
...
```
能看到`lo0`，表示本地回环接口，对应的地址，就是我们前面提到的`127.0.0.1`，也就是回环地址。

和`enp4s0`，表示本机第一块网卡，对应的IP地址是`192.168.31.6`，管它叫本机IP。

`ping`本机IP 跟`ping`回环地址一样，相关的网络数据，都是走的`lo0`，本地回环接口，也就是前面提到的"假网卡"。

只要走了本地回环接口，那数据都不会发送到网络中，在本机网络协议栈中兜一圈，就发回来了。因此`ping`回环地址和`ping`本机地址没有区别。
## 127.0.0.1 和 localhost 以及 0.0.0.0 有区别吗
首先`localhost`就不叫 IP，它是一个域名，就跟`baidu.com`是一个形式的东西，只不过默认会把它解析为`127.0.0.1`，当然这可以在`/etc/hosts`文件下进行修改。

所以默认情况下，使用`localhost`跟使用`127.0.0.1`确实是没区别的。

其次就是`0.0.0.0`，执行`ping 0.0.0.0`，是会失败的，因为它在 IPV4 中表示的是无效的目标地址。
```
$ ping 0.0.0.0
PING 0.0.0.0 (0.0.0.0): 56 data bytes
ping: sendto: No route to host
ping: sendto: No route to host
```
但它还是很有用处的，回想下，我们启动服务器的时候，一般会`listen`一个 IP 和端口，等待客户端的连接。

如果此时`listen`的是本机的`0.0.0.0`, 那么它表示本机上的所有 IPV4 地址。
```
/* Address to accept any incoming messages. */
#define    INADDR_ANY      ((unsigned long int) 0x00000000) /* 0.0.0.0   */
```
举个例子。刚刚提到的`127.0.0.1`和`192.168.31.6`，都是本机的IPV4地址，如果监听`0.0.0.0`，那么用上面两个地址，都能访问到这个服务器。

当然，客户端`connect`时，不能使用`0.0.0.0`。必须指明要连接哪个服务器IP。
### 总结
`127.0.0.1`是回环地址。`localhost`是域名，但默认等于`127.0.0.1`。

`ping`回环地址和`ping`本机地址，是一样的，走的是`lo0`"假网卡"，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前狠狠拐了个弯， 将数据插入到一个链表后就软中断通知`ksoftirqd`来进行收数据的逻辑，压根就不出网络。所以断网了也能`ping`通回环地址。

如果服务器`listen`的是`0.0.0.0`，那么此时用`127.0.0.1`和本机地址都可以访问到服务。
# HTTP 长连接和 TCP 长连接有区别？
事实上，这两个完全是两样不同东西，实现的层面也不同：
* HTTP 的`Keep-Alive`，是由应用层（用户态） 实现的，称为 HTTP 长连接；
* TCP 的`Keepalive`，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制；

## HTTP 的 Keep-Alive
HTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。

由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP  请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。

{% asset_img 4.png 一个HTTP请求 %}

如果每次请求都要经历这样的过程：建立 TCP -> 请求资源 -> 响应资源 -> 释放连接，那么此方式就是 HTTP 短连接，如下图：

{% asset_img 5.png HTTP短连接 %}

这样实在太累人了，一次连接只能请求一次资源。

能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？

当然可以，HTTP 的`Keep-Alive`就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。

{% asset_img 6.png HTTP长连接 %}

HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。

怎么才能使用 HTTP 的`Keep-Alive`功能？

在 HTTP 1.0 中默认是关闭的，如果浏览器要开启`Keep-Alive`，它必须在请求的包头中添加：
```
Connection: Keep-Alive
```
然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：
```
Connection: Keep-Alive
```
这样做，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端提出断开连接。

从 HTTP 1.1 开始， 就默认是开启了`Keep-Alive`，如果要关闭`Keep-Alive`，需要在 HTTP 请求的包头里添加：
```
Connection:close
```
现在大多数浏览器都默认是使用 HTTP/1.1，所以`Keep-Alive`都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。

HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 HTTP 流水线技术提供了可实现的基础。

所谓的 HTTP 流水线，是客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应，可以减少整体的响应时间。

举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。HTTP 流水线机制则允许客户端同时发出 A 请求和 B 请求。

{% asset_img 7.png 右边为HTTP流水线机制 %}

但是服务器还是按照顺序响应，先回应 A 请求，完成后再回应 B 请求。

而且要等服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了「队头阻塞」的问题。

可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？

对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供`keepalive_timeout`参数，用来指定 HTTP 长连接的超时时间。

比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。

{% asset_img 8.png HTTP长连接超时 %}

## TCP 的 Keepalive
TCP 的`Keepalive`这东西其实就是 TCP 的保活机制。

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。
* 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。
* 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。
所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。

{% asset_img 9.png TCP保活机制 %}

注意，应用程序若想使用 TCP 保活机制需要通过`socket`接口设置`SO_KEEPALIVE`选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。
## 总结
HTTP 的`Keep-Alive`也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

TCP 的`Keepalive`也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。
# UDP 一定比 TCP 快吗？
## 使用socket进行数据传输
作为一个程序员，假设我们需要在A电脑的进程发一段数据到B电脑的进程，我们一般会在代码里使用`socket`进行编程。

`socket`就像是一个电话或者邮箱。当你想要发送消息的时候，拨通电话或者将信息塞到邮箱里，`socket`内核会自动完成将数据传给对方的这个过程。

基于`socket`我们可以选择使用 TCP 或 UDP 协议进行通信。

对于 TCP 这样的可靠性协议，每次消息发出后都能明确知道对方收没收到。而UDP就像是给邮政的信箱寄信一样，你寄出去的信，根本就不知道对方有没有正常收到，丢了也是有可能的。

回到`socket`编程的话题上。

创建`socket`的方式就像下面这样。
```
fd = socket(AF_INET, 具体协议,0);
```
注意上面的"具体协议"，如果传入的是`SOCK_STREAM`，是指使用字节流传输数据，说白了就是 TCP 协议。

如果传入的是`SOCK_DGRAM`，是指使用数据报传输数据，也就是 UDP 协议。

返回的`fd`是指`socket`句柄，可以理解为`socket`的身份证号。通过这个`fd`你可以在内核中找到唯一的`socket`结构。

如果想要通过这个`socket`发消息，只需要操作这个`fd`就行了，比如执行`send(fd, msg, ...)`，内核就会通过这个`fd`句柄找到`socket`然后进行发数据的操作。

如果一切顺利，此时对方执行接收消息的操作，也就是`recv(fd, msg, ...)`，就能拿到你发的消息。

{% asset_img 10.gif udp发送接收过程 %}

## 对于异常情况的处理
但如果不顺利呢？比如消息发到一半，丢包了呢?

丢包的原因有很多。那 UDP 和 TCP 的态度就不太一样了。

UDP 表示，"哦，是吗？然后呢？关我x事"

TCP 态度就截然相反了，"啊？那可不行，是不是我发太快了呢？是不是链路太堵被别人影响到了呢？不过你放心，我肯定给你补发"

TCP 老实人石锤了。我们来看下这个老实人在背后都默默做了哪些事情。
### 重传机制
对于 TCP，它会给发出的消息打上一个编号（`sequence`），接收方收到后回一个确认(`ack`)。发送方可以通过ack的数值知道接收方收到了哪些`sequence`的包。

如果长时间等不到对方的确认，TCP 就会重新发一次消息，这就是所谓的重传机制。

{% asset_img 11.png TCP重传 %}

### 流量控制机制
但重传这件事本身对性能影响是比较严重的，所以是下下策。

于是 TCP 就需要思考有没有办法可以尽量避免重传。

因为数据发送方和接收方处理数据能力可能不同，因此如果可以根据双方的能力去调整发送的数据量就好了，于是就有了发送和接收窗口，基本上从名字就能看出它的作用，比如接收窗口的大小就是指，接收方当前能接收的数据量大小，发送窗口的大小就指发送方当前能发的数据量大小。TCP 根据窗口的大小去控制自己发送的数据量，这样就能大大减少丢包的概率。

{% asset_img 12.png 流量控制机制 %}

### 滑动窗口机制
接收方的接收到数据之后，会不断处理，处理能力也不是一成不变的，有时候处理的快些，那就可以收多点数据，处理的慢点那就希望对方能少发点数据。毕竟发多了就有可能处理不过来导致丢包，丢包会导致重传，这可是下下策。因此我们需要动态的去调节这个接收窗口的大小，于是就有了滑动窗口机制。

看到这里大家可能就有点迷了，流量控制和滑动窗口机制貌似很像，它们之间是啥关系？我总结一下。其实现在 TCP 是通过滑动窗口机制来实现流量控制机制的。

{% asset_img 13.png 滑动窗口机制 %}

### 拥塞控制机制
但这还不够，有时候发生丢包，并不是因为发送方和接收方的处理能力问题导致的。而是跟网络环境有关，大家可以将网络想象为一条公路。马路上可能堵满了别人家的车，只留下一辆车的空间。那就算你家有5辆车，目的地也正好有5个停车位，你也没办法同时全部一起上路。于是 TCP 希望能感知到外部的网络环境，根据网络环境及时调整自己的发包数量，比如马路只够两辆车跑，那我就只发两辆车。但外部环境这么复杂，TCP 是怎么感知到的呢？

TCP 会先慢慢试探的发数据，不断加码数据量，越发越多，先发一个，再发2个，4个…。直到出现丢包，这样 TCP 就知道现在当前网络大概吃得消几个包了，这既是所谓的拥塞控制机制。

不少人会疑惑流量控制和拥塞控制的关系。我这里小小的总结下。流量控制针对的是单个连接数据处理能力的控制，拥塞控制针对的是整个网络环境数据处理能力的控制。
### 分段机制
但上面提到的都是怎么降低重传的概率，似乎重传这个事情就是无法避免的，那如果确实发生了，有没有办法降低它带来的影响呢？

有。当我们需要发送一个超大的数据包时，如果这个数据包丢了，那就得重传同样大的数据包。但如果我能将其分成一小段一小段，那就算真丢了，那我也就只需要重传那一小段就好了，大大减小了重传的压力，这就是 TCP 的分段机制。

而这个所谓的一小段的长度，在传输层叫 MSS（Maximum Segment Size），数据包长度大于 MSS 则会分成N个小于等于 MSS 的包。

{% asset_img 14.gif MSS分包 %}

而在网络层，如果数据包还大于 MTU（Maximum Transmit Unit），那还会继续分包。

{% asset_img 15.gif MTU分包 %}

一般情况下，`MSS=MTU-40Byte`，所以 TCP 分段后，到了 IP 层大概率就不会再分片了。

{% asset_img 16.png MSS和MTU的区别 %}

### 乱序重排机制
既然数据包会被分段，链路又这么复杂还会丢包，那数据包乱序也就显得不奇怪了。比如发数据包1,2,3。1号数据包走了其他网络路径，2和3数据包先到，1数据包后到，于是数据包顺序就成了2,3,1。这一点 TCP 也考虑到了，依靠数据包的`sequence`，接收方就能知道数据包的先后顺序。

后发的数据包先到是吧，那就先放到专门的乱序队列中，等数据都到齐后，重新整理好乱序队列的数据包顺序后再给到用户，这就是乱序重排机制。

{% asset_img 17.png 乱序队列等待数据包的到来 %}

### 连接机制
UDP 是无连接的，而 TCP 是面向连接的。这里提到的连接到底是啥？

TCP 通过上面提到的各种机制实现了数据的可靠性。这些机制背后是通过一个个数据结构来实现的逻辑。而为了实现这套逻辑，操作系统内核需要在两端代码里维护一套复杂的状态机（三次握手，四次挥手，RST，closing等异常处理机制），这套状态机其实就是所谓的"连接"。这其实就是 TCP 的连接机制，而 UDP 用不上这套状态机，因此它是"无连接"的。

网络环境链路很长，还复杂，数据丢包是很常见的。

我们平常用 TCP 做各种数据传输，完全对这些事情无感知。

这就是TCP三大特性"面向连接、可靠的、基于字节流"中"可靠"的含义。
### 用UDP就一定比用TCP快吗？
这时候 UDP 就不服了："正因为没有这些复杂的 TCP 可靠性机制，所以我很快啊"

嗯，这也是大部分人认为 UDP 比 TCP 快的原因。

实际上大部分情况下也确实是这样的。

那有没有用了 UDP 但却比 TCP 慢的情况呢？

其实也有。

在回答这个问题前，我需要先说下 UDP 的用途。

实际上，大部分人也不会尝试直接拿裸 UDP 放到生产环境中去做项目。

那 UDP 的价值在哪？

UDP 的存在，本质是内核提供的一个最小网络传输功能。

很多时候，大家虽然号称自己用了 UDP，但实际上都很忌惮它的丢包问题，所以大部分情况下都会在 UDP 的基础上做各种不同程度的应用层可靠性保证。比如王者农药用的 KCP，以及 QUIC（HTTP3.0），其实都在 UDP 的基础上做了重传逻辑，实现了一套类似 TCP 那样的可靠性机制。

教科书上最爱提 UDP 适合用于音视频传输，因为这些场景允许丢包。但其实也不是什么包都能丢的，比如重要的关键帧啥的，该重传还得重传。除此之外，还有一些乱序处理机制。举个例子吧。

打音视频电话的时候，你可能遇到过丢失中间某部分信息的情况，但应该从来没遇到过乱序的情况吧。

所以说，虽然选择了使用 UDP，但一般还是会在应用层上做一些重传机制的。

于是问题就来了，如果现在我需要传一个特别大的数据包。

在 TCP 里，它内部会根据 MSS 的大小分段，这时候进入到 IP 层之后，每个包大小都不会超过 MTU，因此 IP 层一般不会再进行分片。这时候发生丢包了，只需要重传每个 MSS 分段就够了。

{% asset_img 18.png TCP分段 %}

但对于 UDP，其本身并不会分段，如果数据过大，到了 IP 层，就会进行分片。此时发生丢包的话，再次重传，就会重传整个大数据包。

{% asset_img 19.png UDP不分段 %}

对于上面这种情况，使用 UDP 就比 TCP 要慢。

当然，解决起来也不复杂。这里的关键点在于是否实现了数据分段机制，使用 UDP 的应用层如果也实现了分段机制的话，那就不会出现上述的问题了。
## 总结
TCP 为了实现可靠性，引入了重传机制、流量控制、滑动窗口、拥塞控制、分段以及乱序重排机制。而 UDP 则没有实现，因此一般来说 TCP 比 UDP 慢。

TCP 是面向连接的协议，而 UDP 是无连接的协议。这里的"连接"其实是，操作系统内核在两端代码里维护的一套复杂状态机。

大部分项目，会在基于 UDP 的基础上，模仿TCP，实现不同程度的可靠性机制。比如王者农药用的KCP其实就在基于UDP在应用层里实现了一套重传机制。

对于 UDP+重传的场景，如果要传超大数据包，并且没有实现分段机制的话，那数据就会在 IP 层分片，一旦丢包，那就需要重传整个超大数据包。而 TCP 则不需要考虑这个，内部会自动分段，丢包重传分段就行了。这种场景下 TCP 更快。
