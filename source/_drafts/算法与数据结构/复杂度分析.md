

# 大 O 复杂度表示法
算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？

这里有段非常简单的代码，求 1,2,3…n 的累加和。
```c++
int cal(int n) {
  int sum = 0;
  int i = 1;
  for (; i <= n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```
从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为`unit_time`。

在这个假设的基础之上，第 2、3 行代码分别需要 1 个`unit_time`的执行时间，第 4、5 行都运行了`n`遍，所以需要`2n*unit_time`的执行时间，所以这段代码总的执行时间就是`(2n+2)*unit_time`。可以看出来，所有代码的执行时间`T(n)`与每行代码的执行次数成正比。

按照这个分析思路，我们再来看这段代码。
```c++
int cal(int n) {
  int sum = 0;
  int i = 1;
  int j = 1;
  for (; i <= n; ++i) {
    j = 1;
    for (; j <= n; ++j) {
      sum = sum +  i * j;
    }
  }
}
```
我们依旧假设每个语句的执行时间是`unit_time`。第 2、3、4 行代码，每行都需要 1 个`unit_time`的执行时间，第 5、6 行代码循环执行了`n`遍，需要`2n * unit_time`的执行时间，第 7、8 行代码循环执行了 n^2 遍，所以需要`2n^2 * unit_time`的执行时间。所以，整段代码总的执行时间`T(n) = (2n^2+2n+3)*unit_time`。

尽管我们不知道`unit_time`的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，所有代码的执行时间`T(n)`与每行代码的执行次数`n`成正比。

我们可以把这个规律总结成一个公式。
```
T(n) = O(f(n))
```
其中，`T(n)`表示代码执行的时间；`n`表示数据规模的大小；`f(n)`表示每行代码执行的次数总和。因为这是一个公式，所以用`f(n)`来表示。公式中的`O`，表示代码的执行时间`T(n)`与`f(n)`表达式成正比。

所以，第一个例子中的`T(n) = O(2n+2)`，第二个例子中的`T(n) = O(2n2+2n+3)`。这就是大`O`时间复杂度表示法。大`O`时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度，简称时间复杂度。

当`n`很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：`T(n) = O(n)`；`T(n) = O(n2)`。
# 时间复杂度分析
如何分析一段代码的时间复杂度？
## 1. 只关注循环执行次数最多的一段代码
大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的`n`的量级，就是整段要分析代码的时间复杂度。
```c++
int cal(int n) {
  int sum = 0;
  int i = 1;
  for (; i <= n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```
其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。
## 2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
```c++
int cal(int n) {
  int sum_1 = 0;
  int p = 1;
  for (; p < 100; ++p) {
    sum_1 = sum_1 + p;
  }

  int sum_2 = 0;
  int q = 1;
  for (; q < n; ++q) {
    sum_2 = sum_2 + q;
  }

  int sum_3 = 0;
  int i = 1;
  int j = 1;
  for (; i <= n; ++i) {
    j = 1; 
    for (; j <= n; ++j) {
      sum_3 = sum_3 +  i * j;
    }
  }

  return sum_1 + sum_2 + sum_3;
}
```
这个代码分为三部分，分别是求`sum_1、sum_2、sum_3`。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。

第一段代码循环执行了 100 次，所以是一个常量的执行时间，跟`n`的规模无关。

这里要强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟`n`无关，照样也是常量级的执行时间。当`n`无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

那第二段代码和第三段代码的时间复杂度是多少呢？答案是`O(n)`和`O(n^2)`。

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为`O(n^2)`。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：
如果`T1(n)=O(f(n))，T2(n)=O(g(n))；`那么`T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))`。
## 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
如果`T1(n)=O(f(n))，T2(n)=O(g(n))；`那么`T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))`。

也就是说，假设`T1(n) = O(n)`，`T2(n) = O(n2)`，则`T1(n) * T2(n) = O(n3)`。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环。
```c++
int cal(int n) {
  int ret = 0; 
  int i = 1;
  for (; i < n; ++i) {
    ret = ret + f(i);
  } 
} 

int f(int n) {
int sum = 0;
int i = 1;
for (; i < n; ++i) {
  sum = sum + i;
} 
return sum;
}
```
我们单独看`cal()`函数。假设`f()`只是一个普通的操作，那第 4～6 行的时间复杂度就是，`T1(n) = O(n)`。但`f()`函数本身不是一个简单的操作，它的时间复杂度是`T2(n) = O(n)`，所以，整个`cal()`函数的时间复杂度就是，`T(n) = T1(n) * T2(n) = O(n*n) = O(n2)`。
# 几种常见时间复杂度实例分析
* 常亮阶：`O(1)`
* 指数阶：`O(2^n)`
* 对数阶：`O(logn)`
* 阶乘阶：`O(n!)`
* 线性阶：`O(n)`
* 线性对数阶：`O(nlogn)`
* 平方阶：`O(n^2)`、立方阶：`O(n^3)`....k次方阶：`O(n^k)`

对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：`O(2^n)`和`O(n!)`。

当数据规模`n`越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。我们主要来看几种常见的多项式时间复杂度。
## 1. O(1)
首先你必须明确一个概念，`O(1)`只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是`O(1)`，而不是`O(3)`。
```c++
int i = 8;
int j = 6;
int sum = i + j;
```
只要代码的执行时间不随`n`的增大而增长，这样代码的时间复杂度我们都记作`O(1)`。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是`Ο(1)`。
## 2. O(logn)、O(nlogn)
对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。
```c++
i=1;
while (i <= n)  {
  i = i * 2;
}
```
第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量`i`的值从 1 开始取，每循环一次就乘以 2。当大于`n`时，循环结束。实际上，变量`i`的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：
```
2^0 2^1 2^2 ... 2^k ... 2^x = n
```
所以，我们只要知道`x`值是多少，就知道这行代码执行的次数了。`x=log2n`，所以，这段代码的时间复杂度就是`O(log2n)`。

现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？
```c++
i = 1;
while (i <= n)  {
  i = i * 3;
}
```
这段代码的时间复杂度为`O(log3n)`。

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为`O(logn)`。为什么呢？

我们知道，对数之间是可以互相转换的，`log3n`就等于`log32 * log2n`，所以`O(log3n) = O(C * log2n)`，其中`C=log32`是一个常量。基于我们前面的一个理论：在采用大`O`标记复杂度的时候，可以忽略系数，即`O(Cf(n)) = O(f(n))`。所以，`O(log2n)`就等于`O(log3n)`。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为`O(logn)`。

如果你理解了`O(logn)`，那`O(nlogn)`就很容易理解了。如果一段代码的时间复杂度是`O(logn)`，我们循环执行`n`遍，时间复杂度就是`O(nlogn)`了。而且，`O(nlogn)`也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是`O(nlogn)`。
## 3. O(m+n)、O(m*n)
代码的复杂度由两个数据的规模来决定。
```c++
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
```
从代码中可以看出，`m`和`n`是表示两个数据规模。我们无法事先评估`m`和`n`谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是`O(m+n)`。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：`T1(m) + T2(n) = O(f(m) + g(n))`。但是乘法法则继续有效：`T1(m)*T2(n) = O(f(m) * f(n))`。
# 空间复杂度分析
时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。
```c++
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
 
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```
跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量`i`，但是它是常量阶的，跟数据规模`n`没有关系，所以我们可以忽略。第 3 行申请了一个大小为`n`的`int`类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是`O(n)`。

我们常见的空间复杂度就是`O(1)、O(n)、O(n2)`，像`O(logn)、O(nlogn)`这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握这些内容已经足够了。
# 最好、最坏情况时间复杂度
上一节我举的分析复杂度的例子都很简单，今天我们来看一个稍微复杂的。你可以用我上节教你的分析技巧，自己先试着分析一下这段代码的时间复杂度。
```c++
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) pos = i;
  }
  return pos;
}
```
你应该可以看出来，这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。按照上节课讲的分析方法，这段代码的复杂度是 O(n)，其中，n 代表数组的长度。

我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。
```c++
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```
这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 O(n) 吗？很显然，咱们上一节讲的分析方法，解决不了这个问题。

因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。

顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。
# 平均情况时间复杂度
我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。

平均时间复杂度又该怎么分析呢？我还是借助刚才查找变量 x 的例子来给你解释。

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：